from torchvision.models.detection import fasterrcnn_resnet50_fpn
from PIL import Image, ImageDraw, ImageFilter, ImageFont
import numpy as np
import torch
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import albumentations as A
from albumentations.pytorch.transforms import ToTensorV2
import gradio as gr

def show_bb(img, preds, score_lim = 0.3, chosen_blur =None):
    # A single prediction on the image
    #   each prediction containing multiple
    #   bounding boxes with attached scores
    pred = preds[0]
    boxes = pred["boxes"]
    scores = pred["scores"]

    # Used to draw bounding boxes and 
    #   write text on the image
    pil = img
    pildraw = ImageDraw.Draw(pil)

    boxes_cnt = 0
    for i, b in enumerate(boxes):
        # Used to filter the bounding boxes
        #   based on the confidence score that the
        #   detection in the bounding box is indeed 
        #   a person face
        if scores[i] >= score_lim:
            xmin = round(b[0].item())
            ymin = round(b[1].item())
            xmax = round(b[2].item())
            ymax = round(b[3].item())

            # Used if the user presses the blur
            #   button, and chosen_blur is the 
            #   list of boxes selected by the user
            if chosen_blur:
                if boxes_cnt in chosen_blur:
                    # Draw a mask that contains the blur
                    mask = Image.new('L', pil.size, 0)
                    draw = ImageDraw.Draw(mask)
                    draw.rectangle([(xmin, ymin), (xmax, ymax) ], fill=255)
                    blurred = pil.filter(ImageFilter.GaussianBlur(30))

                    # Pasting the mask on the original picture
                    pil.paste(blurred, mask=mask)
            else:
                # If the user only pressed the run button
                #   we have to draw the rectangles and the
                #   number of the box, so that
                #   the user can then choose the boxes
                #   that he wants to blur
                pildraw.rectangle([(xmin, ymin), (xmax, ymax)], outline="red", width=3)
                
                # This is needed inside the folder where the application
                #   is run from
                font = ImageFont.truetype("Roboto-Light.ttf", 20)
                pildraw.text((xmin, ymin), str(boxes_cnt), font=font, align ="left", fill="black") 

            # Used for the list of checkboxes
            boxes_cnt += 1
    return pil, boxes_cnt
    

# FasterRCNN Model
net = fasterrcnn_resnet50_fpn()
net.roi_heads.box_predictor = FastRCNNPredictor(net.roi_heads.box_predictor.cls_score.in_features, 2)

# Loading the model on which we did transfer learning
net.load_state_dict(torch.load("faster_rcnn_10.h5", map_location=torch.device('cpu')))

# The transformations needed by the model
transform = A.Compose([A.Normalize(mean=0, std=1, always_apply=True), ToTensorV2(p=1.0)])

# Used to save the list of bounding boxes
prediction = None

def predict(img, confidence):

    # Default
    if not confidence:
        confidence = 0.5
    transformed_image = transform(image=np.array(img.convert("L")))["image"].unsqueeze(0)
    
    net.eval()
    with torch.no_grad():
        global prediction
        prediction = net(transformed_image)

        # Get image with bounding boxes and number of boxes
        with_bb, bbs = show_bb(img, prediction, confidence)

        # Substitute the image in the UI,
        #   set the slider to the chosen confidence
        #   and generate che checkboxes
        return [
            with_bb, 
            gr.Slider(0, 1, value=0.5, label="Confidence", visible=True),
            gr.CheckboxGroup([i for i in range(bbs)], interactive=True)
        ]

# Triggered when the confidence slider is changed
def change_confid(img, confidence):
    # The image with boxes is regenerated by using the existent
    #   prediction, without calculating a new one
    with_bb, bbs = show_bb(img, prediction, confidence)

    # Substitute the picture with boxes and the checkboxes
    return [
        with_bb,
        gr.CheckboxGroup([i for i in range(bbs)], interactive=True)
    ]

# Triggered when the generate blur button is pressed
def blur_image(img, bb_to_blur, confidence):
    # Generate the picture but with blur instead of
    #   red boxes
    with_bb, _ = show_bb(img, prediction, confidence, bb_to_blur)
    return with_bb

with gr.Blocks() as demo:
    with gr.Row():
        with gr.Column():
            # Image to be selected or webcam
            input_image = gr.Image(type="pil")

            # Button to run the prediction on the image
            run_button = gr.Button("Run")
        
        # Image with prediction boxes
        output_bb = gr.Image(interactive=False)
        
        with gr.Column():
            # Image with blurred boxes over selected faces
            blurred_image = gr.Image(interactive=False)

            # Button to render the blurred image from
            #   selected faces
            render_button = gr.Button("Render")

    # Confidence slider
    confid = gr.Slider(0, 1, value=0.5, label="Confidence", visible=False)

    # TODO: On hover bring to front and make the selected bb bigger
    # on the picture in output
    pred_list = gr.CheckboxGroup([], interactive=True)

    # Prediction Click Event
    run_button.click(
        predict, 
        [input_image, confid], 
        [output_bb, confid, pred_list]
    )

    # Confidence 
    confid.change(
        change_confid, 
        [input_image, confid], 
        [output_bb, pred_list]
    )

    render_button.click(
        blur_image,
        [input_image, pred_list, confid],
        blurred_image
    )

if __name__ == "__main__":
    demo.queue().launch(show_api=False)